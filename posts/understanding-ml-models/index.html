<!doctype html><html lang=en><head><head><meta charset=utf-8><title>Satwik Kambham's Blog</title><meta name=description content><meta name=author content><meta name=viewport content="width=device-width,initial-scale=1"><link href="https://fonts.googleapis.com/css?family=Raleway:400,300,600" rel=stylesheet type=text/css><link href="https://fonts.googleapis.com/css?family=Caveat:400,300,600" rel=stylesheet type=text/css><link rel=stylesheet href=https://code-explorer.github.io/blog//css/normalize.css><link rel=stylesheet href=https://code-explorer.github.io/blog//css/skeleton.css><link rel=stylesheet href=https://code-explorer.github.io/blog//css/custom.css><link rel="shortcut icon" href=https://code-explorer.github.io/blog//images/favicon.ico type=image/x-icon><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body);></script></head></head><body><header><dir class=container><section class=header><a href=https://code-explorer.github.io/blog/><h2>Satwik Kambham</h2></a><div class=row><div class="four columns"><a href=https://linkedin.com/in/satwik-kambham/>Linkedin</a></div><div class="four columns"><a href=https://code-explorer.github.io/>Portfolio</a></div><div class="four columns"><a href=https://github.com/code-explorer>GitHub</a></div></div></section></dir></header><div id=content><div class=container><h1 class=title>Understanding Supervised Machine Learning Models</h1><div class=title><p><time>July 7, 2022</time> |
4 minutes read</p></div><div class=content><p>A machine learning model functions like any other algorithm in that it takes some input and produces some output base on the input.</p><image src=MLModel.svg class=u-full-width><p>The main difference between a machine learning model and a traditional algorithm lies in the way they are created. A supervised machine learning model is created using what is known as training data. The training data is a small collection of inputs and their corresponding outputs that we know to be accurate. The model utilizes the training data to find a common pattern between the inputs and the outputs.</p><p>To further understand how a machine learning model is created let us create a very simple model that finds the correlation between a person&rsquo;s height and their shoe size.</p><blockquote><p><em><strong>Note</strong>: For this example, I am using python and numpy. But you should be able use the same principle in any other language.</em></p></blockquote><h2 id=predicting-shoe-size-based-on-height>Predicting shoe size based on height</h2><table><thead><tr><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>Input (Height in inches)</td><td>56</td><td>60</td><td>63</td><td>64</td><td>67</td><td>68</td><td>70</td></tr><tr><td>Output (Shoe Size)</td><td>7.31</td><td>8.25</td><td>9.15</td><td>9.18</td><td>10</td><td>10.02</td><td>10.81</td></tr></tbody></table><p>If we visualize this data we can see that the relationship between the height and the shoe size is linear.</p><image src=height-shoe_size.jpg class=u-full-width><p>So, we can use the equation of a line to create the model:</p><p>$$ y = mx + c $$</p><p>Here,<br>x is the input,<br>y is the output and<br>m and c are the parameters of the model which we will try to find.</p><p>The training process will allow the model to find the parameters ( m and c) of the line.</p><h3 id=training-the-model>Training the model</h3><image src=TrainingMLModel.svg class=u-full-width><p>The model is trained using a process called <strong>Gradient Descent</strong>. Gradient Descent is a method to find the parameters which minimize the error of our model. It works by progressively updating the parameters of the model based on the error of the model.</p><p>The <strong>Cost Function</strong> tells us how far off the predicts of our model are from the training data.</p><p>We can break down the training process into the following steps:</p><ol><li>Make predictions for the training data.</li><li>Calculate the cost using the cost function.</li><li>Update the parameters of the model using the cost.</li></ol><p>To train our model we repeat the above steps until we are satisfied with the model. So lets get started!</p><h4 id=linear-regression>Linear Regression</h4><p>The model we are training is a <strong>Linear Regression</strong> model. A linear regression model tries to find a straight line that best fits the data.</p><blockquote><p>The same principles used to create a linear regression model also carry over to other supervised machine learning models.</p></blockquote><h4 id=initializing-the-parameters>Initializing the parameters</h4><p>We start by initializing the parameters ( m and c ) of the model.
We can either initialize them to random values or we can initialize them to zero.</p><p>For this example, we will just initialize them to zero.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>m <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
c <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</code></pre></div><h4 id=defining-the-model>Defining the model</h4><p>To make the predicts the use the line equation as discussed above:
$$ y = mx + c $$</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>predict</span>(x):
    <span style=color:#66d9ef>return</span> m <span style=color:#f92672>*</span> x <span style=color:#f92672>+</span> c
</code></pre></div><p>This process is also called <strong>forward propagation</strong>.</p><h4 id=calculating-the-cost>Calculating the cost</h4><p>To calculate the cost for our linear regression model, we can use one of the following cost functions:</p><ol><li>Mean Absolute Error (MAE)
$$ \frac 1 n \sum_{i=1}^n |y - \hat y|$$</li><li>Mean Squared Error (MSE)
$$ \frac 1 n \sum_{i=1}^n (y - \hat y)^2 $$</li></ol><blockquote><p><em><strong>Note</strong>: y refers to the actual value and y hat refers to the predicted value</em></p></blockquote><p>For this example we are going to use the Mean Squared Error (MSE) cost function.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>cost</span>(y, y_hat):
    <span style=color:#66d9ef>return</span> np<span style=color:#f92672>.</span>sum((y <span style=color:#f92672>-</span> y_hat) <span style=color:#f92672>**</span> <span style=color:#ae81ff>2</span>) <span style=color:#f92672>/</span> len(y)
</code></pre></div><h4 id=updating-the-parameters>Updating the parameters</h4><p>During each iteration of the training process, we will update each parameter like so:</p><p>$$p = p - LearningRate * \frac{\partial (cost(y, \hat y))}{\partial p} $$</p><blockquote><p>where p is the parameter and the learning rate controls the rate at which the parameters are updated.</p></blockquote><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>gradient_descent</span>(y, y_hat, m, c, learning_rate):
    m <span style=color:#f92672>=</span> m <span style=color:#f92672>-</span> learning_rate <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>sum((y <span style=color:#f92672>-</span> y_hat) <span style=color:#f92672>*</span> x) <span style=color:#f92672>/</span> len(y)
    c <span style=color:#f92672>=</span> c <span style=color:#f92672>-</span> learning_rate <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>sum((y <span style=color:#f92672>-</span> y_hat)) <span style=color:#f92672>/</span> len(y)
    <span style=color:#66d9ef>return</span> m, c
</code></pre></div><h4 id=bringing-it-all-together>Bringing it all together</h4><p>Now we can bring it all together into a single class like so:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>Regression</span>:
    <span style=color:#66d9ef>def</span> __init__(self, x, y):
        self<span style=color:#f92672>.</span>m <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
        self<span style=color:#f92672>.</span>c <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
        self<span style=color:#f92672>.</span>x <span style=color:#f92672>=</span> x
        self<span style=color:#f92672>.</span>y <span style=color:#f92672>=</span> y

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>predict</span>(self, x):
        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>m <span style=color:#f92672>*</span> x <span style=color:#f92672>+</span> self<span style=color:#f92672>.</span>c

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>cost</span>(self):
        y_hat <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>predict(self<span style=color:#f92672>.</span>x)
        <span style=color:#66d9ef>return</span> np<span style=color:#f92672>.</span>sum((y_hat <span style=color:#f92672>-</span> self<span style=color:#f92672>.</span>y) <span style=color:#f92672>**</span> <span style=color:#ae81ff>2</span>) <span style=color:#f92672>/</span> len(self<span style=color:#f92672>.</span>y)

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>gradient_descent</span>(self, learning_rate):
        y_hat <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>predict(self<span style=color:#f92672>.</span>x)
        dm <span style=color:#f92672>=</span> (<span style=color:#f92672>-</span><span style=color:#ae81ff>2</span> <span style=color:#f92672>/</span> len(self<span style=color:#f92672>.</span>y)) <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>sum((self<span style=color:#f92672>.</span>y <span style=color:#f92672>-</span> y_hat) <span style=color:#f92672>*</span> self<span style=color:#f92672>.</span>x)
        dc <span style=color:#f92672>=</span> (<span style=color:#f92672>-</span><span style=color:#ae81ff>2</span> <span style=color:#f92672>/</span> len(self<span style=color:#f92672>.</span>y)) <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>sum((self<span style=color:#f92672>.</span>y <span style=color:#f92672>-</span> y_hat))
        self<span style=color:#f92672>.</span>m <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>m <span style=color:#f92672>-</span> learning_rate <span style=color:#f92672>*</span> dm
        self<span style=color:#f92672>.</span>c <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>c <span style=color:#f92672>-</span> learning_rate <span style=color:#f92672>*</span> dc
        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>cost()

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>train</span>(self, learning_rate, iterations):
        <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(iterations):
            self<span style=color:#f92672>.</span>gradient_descent(learning_rate)
        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>m, self<span style=color:#f92672>.</span>c
</code></pre></div><p>And finally we can train it by specifying the learning rate and the number of iterations.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>model <span style=color:#f92672>=</span> Regression(x, y)
model<span style=color:#f92672>.</span>train(<span style=color:#ae81ff>0.0001</span>, <span style=color:#ae81ff>100</span>)
</code></pre></div><image src=height-shoe_size-regression.jpg class=u-full-width><p>There you have it! We have created a regression model that can predict the shoe size based on the height and vice versa.</p></div><script type=text/javascript>window.onload=function(){var placeholder=document.querySelectorAll('.placeholder');placeholder.forEach(element=>{var smallImage=element.getElementsByClassName('img-small')[0];var img=new Image();img.src=smallImage.getAttribute('src')
img.onload=function(){smallImage.classList.add('loaded')}
var largeImage=new Image();largeImage.srcset=element.getAttribute('data-large');largeImage.src=element.getAttribute('data-large');largeImage.onload=function(){largeImage.classList.add('loaded');}
element.appendChild(largeImage);})};</script></div></div></body></html>